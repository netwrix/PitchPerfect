# AGENTS.md

## ğŸ§  Project Overview

This project is a voice-based sales simulation web app that uses OpenAI APIs to create lifelike, dynamic sales training scenarios. It includes:

- React frontend with Tailwind CSS, Framer Motion, shadcn/ui
- Voice chat via Whisper and Text-to-Speech APIs
- Persistent threads, memory, and tool use via the OpenAI Assistants API
- Microsoft Entra login for user authentication
- Leaderboard with ratings per user attempt

## ğŸ¯ Goals for Codex

When working on this repo, Codex should:

- Prioritize clean, modular React components
- Use Tailwind and shadcn/ui for all UI elements
- Keep all OpenAI API integration logic organized in `lib/openai.ts`
- Use `Whisper` for speech-to-text and `TTS` for text-to-speech
- Scaffold API endpoints in Express or Fastify with separation of concerns
- Use Prisma ORM for database access
- Use OAuth 2.0 via Microsoft Entra ID (Azure AD) for login

## ğŸ—‚ï¸ Folder Structure

/frontend â†’ React UI
/backend â†’ Node.js API server
/lib â†’ API utilities (OpenAI, Whisper, TTS, etc.)
/db â†’ Prisma schema & migrations
/public â†’ Static files


## ğŸ”§ OpenAI Usage Summary

- **Whisper API** â†’ Voice input â†’ transcript
- **Assistants API** â†’ Core agent, tool calling, memory
- **TTS API** â†’ Agent reply â†’ audio output
- Optional: `chat/completions` with `stream=true` for fast text fallback

## ğŸ§± Key Features to Maintain

- Toggle between "simplistic" voice-only view and standard chat+voice view
- Real-time interaction cycle:
  1. User speaks
  2. Whisper â†’ text
  3. Assistant â†’ response
  4. TTS â†’ reply audio
- Leaderboard aggregates average ratings per difficulty/persona
- Microsoft Entra login used to personalize sessions and ratings

## ğŸ“Œ Notes

- All assistants should be persona-driven: Easy, Medium, Hard (CISO, IT Manager, etc.)
- Tool calling must allow dynamic product info lookup and post-call feedback
- Track metadata for every attempt: difficulty, user, persona, rating, transcript

